{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e4940cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Cohen's Kappa Scores for Subjective_Label:\n",
      "Annotators 1 and 2: 0.9509188838527396\n",
      "Annotators 1 and 3: 0.938255307914392\n",
      "Annotators 2 and 3: 0.9704076973806585\n",
      "Subjective_Label: Overall Fleiss' Kappa (for all three annotators): 0.9532307401589681\n",
      "\n",
      "Pairwise Cohen's Kappa Scores for Polarity_Label:\n",
      "Annotators 1 and 2: 0.9685749916475636\n",
      "Annotators 1 and 3: 0.9702006489636448\n",
      "Annotators 2 and 3: 0.9884113634858619\n",
      "\n",
      "Polarity_Label: Overall Fleiss' Kappa (for all three annotators): 0.9757261110912916\n"
     ]
    }
   ],
   "source": [
    "# SUBJECTIVE LABEL\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "\n",
    "# Load CSV file - update the file path if necessary\n",
    "df = pd.read_csv(\"C:/Users/russe/Downloads/4021/1000 iaa/Evaluation Sheet (IAA) - evaluation_sheetv3.csv\")\n",
    "\n",
    "# If your CSV file does not contain headers, you can assign column names manually.\n",
    "# For example, if columns A, B, C, ..., then column C is at index 2, E at index 4, G at index 6:\n",
    "# df.columns = list(\"ABCDEFG...\")  # adjust as necessary\n",
    "# subject_cols = df.iloc[:, [2, 4, 6]]\n",
    "# Otherwise, if your CSV file has proper headers like 'C', 'E', 'G', then:\n",
    "subject_cols = df[['A. subjective_label', 'R. subjective_label', 'L. subjective_label']]\n",
    "\n",
    "# Ensure that the values are integers (0 or 1)\n",
    "subject_cols = subject_cols.astype(int)\n",
    "\n",
    "# --- Pairwise Cohen's Kappa ---\n",
    "# Cohen's kappa measures agreement between two annotators.\n",
    "kappa_CE = cohen_kappa_score(subject_cols['A. subjective_label'], subject_cols['R. subjective_label'])\n",
    "kappa_CG = cohen_kappa_score(subject_cols['A. subjective_label'], subject_cols['L. subjective_label'])\n",
    "kappa_EG = cohen_kappa_score(subject_cols['R. subjective_label'], subject_cols['L. subjective_label'])\n",
    "\n",
    "print(\"Pairwise Cohen's Kappa Scores for Subjective_Label:\")\n",
    "print(\"Annotators 1 and 2:\", kappa_CE)\n",
    "print(\"Annotators 1 and 3:\", kappa_CG)\n",
    "print(\"Annotators 2 and 3:\", kappa_EG)\n",
    "\n",
    "# --- Overall Agreement: Fleiss' Kappa ---\n",
    "# Fleiss' kappa is suitable when more than two raters are involved.\n",
    "# For each entry (row), we need to count how many annotators assigned each category.\n",
    "# In our case, category 0 represents subjective and 1 represents objective.\n",
    "\n",
    "# Create a count matrix where each row corresponds to an entry and\n",
    "# columns correspond to categories (0 and 1).\n",
    "ratings = subject_cols.values  # shape: (n_entries, 3)\n",
    "n_annotations = ratings.shape[1]  # which is 3 in this case\n",
    "\n",
    "# Initialize an array to hold counts for each category per row.\n",
    "# Here, we have two categories: 0 and 1.\n",
    "count_matrix = np.zeros((ratings.shape[0], 2), dtype=int)\n",
    "count_matrix[:, 0] = np.sum(ratings == 0, axis=1)  # count of subjective (0)\n",
    "count_matrix[:, 1] = np.sum(ratings == 1, axis=1)  # count of objective (1)\n",
    "\n",
    "# Calculate Fleiss' kappa using statsmodels. The function expects the data as a 2D array\n",
    "# where each row is a subject (entry) and each column is the count for a particular category.\n",
    "fleiss_kappa_value = fleiss_kappa(count_matrix)\n",
    "print(\"Subjective_Label: Overall Fleiss' Kappa (for all three annotators):\", fleiss_kappa_value)\n",
    "\n",
    "\n",
    "\n",
    "# POLARITY LABEL\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "\n",
    "# Load CSV file - update the file path if necessary\n",
    "df = pd.read_csv(\"C:/Users/russe/Downloads/4021/1000 iaa/Evaluation Sheet (IAA) - evaluation_sheetv3.csv\")\n",
    "\n",
    "# If your CSV file does not contain headers, you can assign column names manually.\n",
    "# For example, if columns A, B, C, ..., then column C is at index 2, E at index 4, G at index 6:\n",
    "# df.columns = list(\"ABCDEFG...\")  # adjust as necessary\n",
    "# subject_cols = df.iloc[:, [2, 4, 6]]\n",
    "# Otherwise, if your CSV file has proper headers like 'C', 'E', 'G', then:\n",
    "subject_cols = df[['A. polarity_label', 'R. polarity_label', 'L. polarity_label']]\n",
    "\n",
    "# Ensure that the values are integers (0 or 1)\n",
    "subject_cols = subject_cols.astype(int)\n",
    "\n",
    "# --- Pairwise Cohen's Kappa ---\n",
    "# Cohen's kappa measures agreement between two annotators.\n",
    "kappa_CE = cohen_kappa_score(subject_cols['A. polarity_label'], subject_cols['R. polarity_label'])\n",
    "kappa_CG = cohen_kappa_score(subject_cols['A. polarity_label'], subject_cols['L. polarity_label'])\n",
    "kappa_EG = cohen_kappa_score(subject_cols['R. polarity_label'], subject_cols['L. polarity_label'])\n",
    "\n",
    "print(\"\\nPairwise Cohen's Kappa Scores for Polarity_Label:\")\n",
    "print(\"Annotators 1 and 2:\", kappa_CE)\n",
    "print(\"Annotators 1 and 3:\", kappa_CG)\n",
    "print(\"Annotators 2 and 3:\", kappa_EG)\n",
    "\n",
    "# --- Overall Agreement: Fleiss' Kappa ---\n",
    "# Fleiss' kappa is suitable when more than two raters are involved.\n",
    "# For each entry (row), we need to count how many annotators assigned each category.\n",
    "# In our case, category 0 represents subjective and 1 represents objective.\n",
    "\n",
    "# Create a count matrix where each row corresponds to an entry and\n",
    "# columns correspond to categories (0 and 1).\n",
    "ratings = subject_cols.values  # shape: (n_entries, 3)\n",
    "# n_annotations = ratings.shape[1]  # which is 3 in this case\n",
    "\n",
    "# Create a count matrix with three columns (one for each category: 0, 1, 2)\n",
    "count_matrix = np.zeros((ratings.shape[0], 3), dtype=int)\n",
    "count_matrix[:, 0] = np.sum(ratings == 0, axis=1)  # Count of label 0\n",
    "count_matrix[:, 1] = np.sum(ratings == 1, axis=1)  # Count of label 1\n",
    "count_matrix[:, 2] = np.sum(ratings == 2, axis=1)  # Count of label 2\n",
    "\n",
    "# Calculate Fleiss' kappa using statsmodels. The function expects the data as a 2D array\n",
    "# where each row is a subject (entry) and each column is the count for a particular category.\n",
    "fleiss_kappa_value = fleiss_kappa(count_matrix)\n",
    "print(\"\\nPolarity_Label: Overall Fleiss' Kappa (for all three annotators):\", fleiss_kappa_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69f4e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUBJECTIVE_LABEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file (update the file path as needed)\n",
    "df = pd.read_csv(\"C:/Users/russe/Downloads/4021/1000 iaa/Evaluation Sheet (IAA) - evaluation_sheetv3.csv\")\n",
    "\n",
    "# Select the columns corresponding to the subjective labels\n",
    "subject_cols = df[['A. subjective_label', 'R. subjective_label', 'L. subjective_label']]\n",
    "\n",
    "# Define a function to compute the majority vote\n",
    "def majority_vote(row):\n",
    "    counts = row.value_counts()\n",
    "    # If the highest frequency is at least 2, return that label.\n",
    "    if counts.iloc[0] >= 2:\n",
    "        return counts.idxmax()\n",
    "    else:\n",
    "        # No majority vote if all values are different, so assign NaN.\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function across each row to create the new column 'Subjective_Label'\n",
    "df['GT_Subjective_Label'] = subject_cols.apply(majority_vote, axis=1)\n",
    "\n",
    "# Optionally, display the first few rows to verify the results\n",
    "# print(df[['C', 'E', 'G', 'Subjective_Label']].head())\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file if desired.\n",
    "df.to_csv(\"C:/Users/russe/Downloads/4021/1000 iaa/Evaluation Sheet (IAA) - evaluation_sheetv5.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d56a6564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBJECTIVE LABEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file (update the file path if necessary)\n",
    "df = pd.read_csv(\"C:/Users/russe/Downloads/4021/1000 iaa/Evaluation Sheet (IAA) - evaluation_sheetv3.csv\")\n",
    "\n",
    "# Select the columns corresponding to the objective labels.\n",
    "# Here, we assume the objective label columns are 'D', 'F', and 'H'\n",
    "polarity_cols = df[['A. polarity_label', 'R. polarity_label', 'L. polarity_label']].astype(int)\n",
    "\n",
    "# Define a function to compute the majority vote for objective labels\n",
    "def majority_vote_objective(row):\n",
    "    counts = row.value_counts()\n",
    "    # If the most frequent label appears at least twice, return it.\n",
    "    if counts.iloc[0] >= 2:\n",
    "        return counts.idxmax()\n",
    "    else:\n",
    "        # If no two labels agree, assign NaN to indicate ambiguity.\n",
    "        return np.nan\n",
    "\n",
    "# Apply the majority vote function across each row to create the new column 'Objective_Label'\n",
    "df['GT_Polarity_Label'] = polarity_cols.apply(majority_vote_objective, axis=1)\n",
    "\n",
    "# Optionally, display the first few rows to verify the results\n",
    "# print(df[['D', 'F', 'H', 'Objective_Label']].head())\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file if desired.\n",
    "df.to_csv(\"C:/Users/russe/Downloads/4021/1000 iaa/Evaluation Sheet (IAA) - evaluation_sheetv6.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
